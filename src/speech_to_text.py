# src/speech_to_text.py
"""
Module Speech-to-Text s·ª≠ d·ª•ng Groq Whisper API.
Ch·ª©c nƒÉng:
1. Transcribe file audio (mp3, wav, m4a)
2. Chia audio th√†nh chunks ƒë·ªÉ x·ª≠ l√Ω streaming
3. H·ªó tr·ª£ ti·∫øng Vi·ªát
"""

import os
import io
import tempfile
from pathlib import Path
from typing import Optional, List, Generator, Tuple

# Groq client ‚Äî import ·ªü ƒë√¢y ƒë·ªÉ property client() c√≥ th·ªÉ d√πng tr·ª±c ti·∫øp
try:
    from groq import Groq
    GROQ_AVAILABLE = True
except ImportError:
    Groq = None
    GROQ_AVAILABLE = False

# Check if pydub is available
try:
    from pydub import AudioSegment
    PYDUB_AVAILABLE = True
except ImportError:
    PYDUB_AVAILABLE = False

# C·∫§U H√åNH
from dotenv import load_dotenv

load_dotenv()

# API Key ‚Äî ∆∞u ti√™n Streamlit secrets (Cloud), fallback v·ªÅ .env (local)
def _get_groq_key() -> str:
    try:
        import streamlit as st
        return st.secrets.get("GROQ_API_KEY", "") or os.getenv("GROQ_API_KEY", "")
    except Exception:
        return os.getenv("GROQ_API_KEY", "")

GROQ_API_KEY = _get_groq_key()

# Model Whisper t·ªët nh·∫•t c·ªßa Groq (h·ªçc t·ª´ groq_whisperer)
WHISPER_MODEL = "whisper-large-v3"

# Kh√¥ng d√πng prompt - ch·ªâ transcribe thu·∫ßn t√∫y t·ª´ audio sang text
DEFAULT_PROMPT = ""

# Chunk duration cho streaming (gi√¢y)
DEFAULT_CHUNK_DURATION = 10  # 10 gi√¢y m·ªói chunk


class SpeechToText:
    """
    Client Speech-to-Text s·ª≠ d·ª•ng Groq Whisper API.
    
    H·ªçc h·ªèi t·ª´ groq_whisperer:
    - C√°ch kh·ªüi t·∫°o Groq client
    - C√°ch g·ªçi audio.transcriptions.create()
    - C√°c parameters quan tr·ªçng: model, prompt, response_format, language
    """
    
    def __init__(
        self, 
        api_key: Optional[str] = None,
        model: str = WHISPER_MODEL,
        language: str = "vi",
        prompt: str = DEFAULT_PROMPT
    ):
        """
        Kh·ªüi t·∫°o Speech-to-Text client.
        
        Args:
            api_key: Groq API key (m·∫∑c ƒë·ªãnh l·∫•y t·ª´ config)
            model: Whisper model name (m·∫∑c ƒë·ªãnh: whisper-large-v3)
            language: Ng√¥n ng·ªØ (m·∫∑c ƒë·ªãnh: vi - ti·∫øng Vi·ªát)
            prompt: Context prompt ƒë·ªÉ c·∫£i thi·ªán accuracy
        """
        self.api_key = api_key or GROQ_API_KEY
        self.model = model
        self.language = language
        self.prompt = prompt
        self._client = None
    
    @property
    def client(self):
        """Lazy initialization c·ªßa Groq client."""
        if self._client is None:
            if not GROQ_AVAILABLE or Groq is None:
                raise RuntimeError(
                    "Th∆∞ vi·ªán groq ch∆∞a ƒë∆∞·ª£c c√†i. Ch·∫°y: pip install groq"
                )
            self._client = Groq(api_key=self.api_key)
        return self._client
    
    def transcribe_file(
        self, 
        audio_path: str,
        prompt: Optional[str] = None,
        language: Optional[str] = None
    ) -> str:
        """
        Transcribe to√†n b·ªô file audio th√†nh text.
        
        H·ªçc t·ª´ groq_whisperer:
        ```python
        transcription = client.audio.transcriptions.create(
            file=(os.path.basename(audio_file_path), file.read()),
            model="whisper-large-v3",
            response_format="text",
            language="en",
        )
        ```
        
        Args:
            audio_path: ƒê∆∞·ªùng d·∫´n file audio (mp3, wav, m4a)
            prompt: Context prompt (optional, override default)
            language: Ng√¥n ng·ªØ (optional, override default)
            
        Returns:
            Transcript text
        """
        try:
            with open(audio_path, "rb") as file:
                # G·ªçi Groq Whisper API (pattern t·ª´ groq_whisperer)
                transcription = self.client.audio.transcriptions.create(
                    file=(os.path.basename(audio_path), file.read()),
                    model=self.model,
                    prompt=prompt or self.prompt,
                    response_format="text",
                    language=language or self.language,
                )
            return transcription
        except Exception as e:
            print(f"‚ùå L·ªói transcribe: {e}")
            return ""
    
    def transcribe_bytes(
        self,
        audio_bytes: bytes,
        filename: str = "audio.wav",
        prompt: Optional[str] = None,
        language: Optional[str] = None
    ) -> str:
        """
        Transcribe audio t·ª´ bytes (cho Streamlit file_uploader).
        
        Args:
            audio_bytes: Audio data d·∫°ng bytes
            filename: T√™n file (ƒë·ªÉ Groq nh·∫≠n di·ªán format)
            prompt: Context prompt (optional)
            language: Ng√¥n ng·ªØ (optional)
            
        Returns:
            Transcript text
        """
        try:
            transcription = self.client.audio.transcriptions.create(
                file=(filename, audio_bytes),
                model=self.model,
                prompt=prompt or self.prompt,
                response_format="text",
                language=language or self.language,
            )
            return transcription
        except Exception as e:
            print(f"‚ùå L·ªói transcribe bytes: {e}")
            return ""
    
    def transcribe_chunks_generator(
        self,
        audio_path: str,
        chunk_duration: int = DEFAULT_CHUNK_DURATION,
        prompt: Optional[str] = None
    ) -> Generator[Tuple[int, float, float, str], None, None]:
        """
        Transcribe audio theo t·ª´ng chunk (STREAMING MODE).
        
        ƒê√¢y l√† ph·∫ßn M·ªöI - kh√¥ng c√≥ trong groq_whisperer.
        Cho ph√©p x·ª≠ l√Ω real-time: m·ªói chunk transcribe xong s·∫Ω yield ngay.
        
        Args:
            audio_path: ƒê∆∞·ªùng d·∫´n file audio
            chunk_duration: ƒê·ªô d√†i m·ªói chunk (gi√¢y)
            prompt: Context prompt
            
        Yields:
            Tuple (chunk_index, start_time, end_time, transcript_text)
        """
        if not PYDUB_AVAILABLE:
            raise RuntimeError("C·∫ßn c√†i pydub ƒë·ªÉ d√πng streaming mode: pip install pydub")
        
        # Load audio
        audio = AudioSegment.from_file(audio_path)
        total_duration = len(audio) / 1000  # milliseconds to seconds
        chunk_ms = chunk_duration * 1000
        
        chunk_index = 0
        
        for start_ms in range(0, len(audio), chunk_ms):
            end_ms = min(start_ms + chunk_ms, len(audio))
            start_sec = start_ms / 1000
            end_sec = end_ms / 1000
            tmp_path = None
            
            try:
                chunk = audio[start_ms:end_ms]
                
                # Export chunk to temporary WAV file
                with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp:
                    chunk.export(tmp.name, format="wav")
                    tmp_path = tmp.name
                
                # Transcribe chunk
                transcript = self.transcribe_file(tmp_path, prompt=prompt)
                
                yield (chunk_index, start_sec, end_sec, transcript, None)
                
            except Exception as e:
                # Tr·∫£ v·ªÅ l·ªói thay v√¨ crash
                error_msg = str(e)
                yield (chunk_index, start_sec, end_sec, "", error_msg)
            finally:
                # Cleanup temp file
                if tmp_path and os.path.exists(tmp_path):
                    os.unlink(tmp_path)
                chunk_index += 1
    
    def transcribe_chunks_from_bytes(
        self,
        audio_bytes: bytes,
        filename: str = "audio.mp3",
        chunk_duration: int = DEFAULT_CHUNK_DURATION,
        prompt: Optional[str] = None
    ) -> Generator[Tuple[int, float, float, str], None, None]:
        """
        Transcribe audio bytes theo t·ª´ng chunk (cho Streamlit upload).
        
        Args:
            audio_bytes: Audio data d·∫°ng bytes
            filename: T√™n file g·ªëc (ƒë·ªÉ detect format)
            chunk_duration: ƒê·ªô d√†i m·ªói chunk (gi√¢y)
            prompt: Context prompt
            
        Yields:
            Tuple (chunk_index, start_time, end_time, transcript_text)
        """
        if not PYDUB_AVAILABLE:
            raise RuntimeError("C·∫ßn c√†i pydub ƒë·ªÉ d√πng streaming mode: pip install pydub")
        
        # Detect format from filename
        ext = Path(filename).suffix.lower().lstrip(".")
        if ext == "m4a":
            ext = "mp4"  # pydub uses mp4 for m4a
        
        # Load audio from bytes
        audio = AudioSegment.from_file(io.BytesIO(audio_bytes), format=ext)
        total_duration = len(audio) / 1000
        chunk_ms = chunk_duration * 1000
        
        chunk_index = 0
        
        for start_ms in range(0, len(audio), chunk_ms):
            end_ms = min(start_ms + chunk_ms, len(audio))
            start_sec = start_ms / 1000
            end_sec = end_ms / 1000
            tmp_path = None
            
            try:
                chunk = audio[start_ms:end_ms]
                
                # Export chunk to temporary WAV file
                with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp:
                    chunk.export(tmp.name, format="wav")
                    tmp_path = tmp.name
                
                # Transcribe chunk
                transcript = self.transcribe_file(tmp_path, prompt=prompt)
                
                yield (chunk_index, start_sec, end_sec, transcript, None)
                
            except Exception as e:
                # Tr·∫£ v·ªÅ l·ªói thay v√¨ crash
                error_msg = str(e)
                yield (chunk_index, start_sec, end_sec, "", error_msg)
            finally:
                # Cleanup temp file
                if tmp_path and os.path.exists(tmp_path):
                    os.unlink(tmp_path)
                chunk_index += 1
    
    def get_audio_duration(self, audio_bytes: bytes, filename: str = "audio.mp3") -> float:
        """L·∫•y t·ªïng th·ªùi l∆∞·ª£ng audio (gi√¢y)."""
        if not PYDUB_AVAILABLE:
            return 0.0
        
        ext = Path(filename).suffix.lower().lstrip(".")
        if ext == "m4a":
            ext = "mp4"
        
        audio = AudioSegment.from_file(io.BytesIO(audio_bytes), format=ext)
        return len(audio) / 1000


# =========================
# HELPER FUNCTIONS
# =========================

# Singleton instance
_stt_instance: Optional[SpeechToText] = None


def get_stt_client() -> SpeechToText:
    """L·∫•y singleton instance c·ªßa SpeechToText."""
    global _stt_instance
    if _stt_instance is None:
        _stt_instance = SpeechToText()
    return _stt_instance


def transcribe_audio(audio_path: str) -> str:
    """
    Helper function - Transcribe file audio.
    
    Args:
        audio_path: ƒê∆∞·ªùng d·∫´n file
        
    Returns:
        Transcript text
    """
    return get_stt_client().transcribe_file(audio_path)


def transcribe_audio_bytes(audio_bytes: bytes, filename: str = "audio.wav") -> str:
    """
    Helper function - Transcribe audio bytes.
    
    Args:
        audio_bytes: Audio data
        filename: T√™n file
        
    Returns:
        Transcript text
    """
    return get_stt_client().transcribe_bytes(audio_bytes, filename)


def transcribe_streaming(
    audio_bytes: bytes, 
    filename: str = "audio.mp3",
    chunk_duration: int = DEFAULT_CHUNK_DURATION
) -> Generator[Tuple[int, float, float, str], None, None]:
    """
    Helper function - Transcribe audio streaming theo chunks.
    
    Args:
        audio_bytes: Audio data
        filename: T√™n file
        chunk_duration: ƒê·ªô d√†i chunk (gi√¢y)
        
    Yields:
        Tuple (chunk_index, start_time, end_time, transcript)
    """
    yield from get_stt_client().transcribe_chunks_from_bytes(
        audio_bytes, filename, chunk_duration
    )


# =========================
# TEST
# =========================

if __name__ == "__main__":
    # Test basic transcription
    print("üé§ Speech-to-Text Module")
    print(f"   Model: {WHISPER_MODEL}")
    print(f"   Language: vi")
    print(f"   Chunk duration: {DEFAULT_CHUNK_DURATION}s")
    
    stt = SpeechToText()
    print(f"‚úÖ Groq client initialized")